{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd482aa1",
   "metadata": {},
   "source": [
    "# Training\n",
    "Here we provide interactive scripts, with which one can train a generative model. The script uses classes and functions used in the code that runs on condor in order to obtain the optimised model trained on the full dataset. \n",
    "We advise not to train the model on the full dataset here as it will take too long. Limit the training dataset size (e.g. use a single input file) and number of epochs and use this notebook to study e.g pre-processing, hyperparameters and diffusion techniques.\n",
    "\n",
    "First, we set the environment and the various parameters for the model, hyperparameters, diffusion equations etc. We also create instances of the stochastic differential equations, machine learning model and create a list of files we want to use as input.\n",
    "\n",
    "Important: need to set the padding value to the value used in pad_events.py script to create the padded (and transformed) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988fc9fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  3 11:05:29 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   60C    P0    29W /  70W |   2001MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "torch version:  1.13.0a0\n",
      "Running on device:  cuda\n",
      "Cuda used to build pyTorch:  11.8\n",
      "Current device:  0\n",
      "Cuda arch list:  ['sm_37', 'sm_50', 'sm_60', 'sm_61', 'sm_70', 'sm_75', 'compute_37']\n",
      "Working directory:  ./\n",
      "['/eos/user/j/jthomasw/tdsm_encoder/datasets/ds2_diff_transforms/dataset_2_padded_nentry424To564.pt']\n",
      "+--------------------------------+-------------------+\n",
      "|          Module name           | Parameters listed |\n",
      "+--------------------------------+-------------------+\n",
      "|           cls_token            |        512        |\n",
      "|          embed.weight          |        2048       |\n",
      "|           embed.bias           |        512        |\n",
      "|        embed_t.1.weight        |       262144      |\n",
      "|         embed_t.1.bias         |        512        |\n",
      "|      dense_t.dense.weight      |        512        |\n",
      "|       dense_t.dense.bias       |         1         |\n",
      "|      dense_e.dense.weight      |        512        |\n",
      "|       dense_e.dense.bias       |         1         |\n",
      "| encoder.0.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.0.attn.in_proj_bias   |        1536       |\n",
      "| encoder.0.attn.out_proj.weight |       262144      |\n",
      "|  encoder.0.attn.out_proj.bias  |        512        |\n",
      "|  encoder.0.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.0.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.0.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.0.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.0.ffnn.0.weight     |       65536       |\n",
      "|     encoder.0.ffnn.0.bias      |        128        |\n",
      "|    encoder.0.ffnn.3.weight     |       65536       |\n",
      "|     encoder.0.ffnn.3.bias      |        512        |\n",
      "|     encoder.0.norm1.weight     |        512        |\n",
      "|      encoder.0.norm1.bias      |        512        |\n",
      "|     encoder.0.norm2.weight     |        512        |\n",
      "|      encoder.0.norm2.bias      |        512        |\n",
      "|     encoder.0.norm3.weight     |        512        |\n",
      "|      encoder.0.norm3.bias      |        512        |\n",
      "| encoder.1.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.1.attn.in_proj_bias   |        1536       |\n",
      "| encoder.1.attn.out_proj.weight |       262144      |\n",
      "|  encoder.1.attn.out_proj.bias  |        512        |\n",
      "|  encoder.1.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.1.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.1.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.1.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.1.ffnn.0.weight     |       65536       |\n",
      "|     encoder.1.ffnn.0.bias      |        128        |\n",
      "|    encoder.1.ffnn.3.weight     |       65536       |\n",
      "|     encoder.1.ffnn.3.bias      |        512        |\n",
      "|     encoder.1.norm1.weight     |        512        |\n",
      "|      encoder.1.norm1.bias      |        512        |\n",
      "|     encoder.1.norm2.weight     |        512        |\n",
      "|      encoder.1.norm2.bias      |        512        |\n",
      "|     encoder.1.norm3.weight     |        512        |\n",
      "|      encoder.1.norm3.bias      |        512        |\n",
      "| encoder.2.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.2.attn.in_proj_bias   |        1536       |\n",
      "| encoder.2.attn.out_proj.weight |       262144      |\n",
      "|  encoder.2.attn.out_proj.bias  |        512        |\n",
      "|  encoder.2.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.2.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.2.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.2.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.2.ffnn.0.weight     |       65536       |\n",
      "|     encoder.2.ffnn.0.bias      |        128        |\n",
      "|    encoder.2.ffnn.3.weight     |       65536       |\n",
      "|     encoder.2.ffnn.3.bias      |        512        |\n",
      "|     encoder.2.norm1.weight     |        512        |\n",
      "|      encoder.2.norm1.bias      |        512        |\n",
      "|     encoder.2.norm2.weight     |        512        |\n",
      "|      encoder.2.norm2.bias      |        512        |\n",
      "|     encoder.2.norm3.weight     |        512        |\n",
      "|      encoder.2.norm3.bias      |        512        |\n",
      "| encoder.3.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.3.attn.in_proj_bias   |        1536       |\n",
      "| encoder.3.attn.out_proj.weight |       262144      |\n",
      "|  encoder.3.attn.out_proj.bias  |        512        |\n",
      "|  encoder.3.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.3.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.3.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.3.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.3.ffnn.0.weight     |       65536       |\n",
      "|     encoder.3.ffnn.0.bias      |        128        |\n",
      "|    encoder.3.ffnn.3.weight     |       65536       |\n",
      "|     encoder.3.ffnn.3.bias      |        512        |\n",
      "|     encoder.3.norm1.weight     |        512        |\n",
      "|      encoder.3.norm1.bias      |        512        |\n",
      "|     encoder.3.norm2.weight     |        512        |\n",
      "|      encoder.3.norm2.bias      |        512        |\n",
      "|     encoder.3.norm3.weight     |        512        |\n",
      "|      encoder.3.norm3.bias      |        512        |\n",
      "| encoder.4.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.4.attn.in_proj_bias   |        1536       |\n",
      "| encoder.4.attn.out_proj.weight |       262144      |\n",
      "|  encoder.4.attn.out_proj.bias  |        512        |\n",
      "|  encoder.4.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.4.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.4.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.4.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.4.ffnn.0.weight     |       65536       |\n",
      "|     encoder.4.ffnn.0.bias      |        128        |\n",
      "|    encoder.4.ffnn.3.weight     |       65536       |\n",
      "|     encoder.4.ffnn.3.bias      |        512        |\n",
      "|     encoder.4.norm1.weight     |        512        |\n",
      "|      encoder.4.norm1.bias      |        512        |\n",
      "|     encoder.4.norm2.weight     |        512        |\n",
      "|      encoder.4.norm2.bias      |        512        |\n",
      "|     encoder.4.norm3.weight     |        512        |\n",
      "|      encoder.4.norm3.bias      |        512        |\n",
      "| encoder.5.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.5.attn.in_proj_bias   |        1536       |\n",
      "| encoder.5.attn.out_proj.weight |       262144      |\n",
      "|  encoder.5.attn.out_proj.bias  |        512        |\n",
      "|  encoder.5.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.5.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.5.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.5.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.5.ffnn.0.weight     |       65536       |\n",
      "|     encoder.5.ffnn.0.bias      |        128        |\n",
      "|    encoder.5.ffnn.3.weight     |       65536       |\n",
      "|     encoder.5.ffnn.3.bias      |        512        |\n",
      "|     encoder.5.norm1.weight     |        512        |\n",
      "|      encoder.5.norm1.bias      |        512        |\n",
      "|     encoder.5.norm2.weight     |        512        |\n",
      "|      encoder.5.norm2.bias      |        512        |\n",
      "|     encoder.5.norm3.weight     |        512        |\n",
      "|      encoder.5.norm3.bias      |        512        |\n",
      "| encoder.6.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.6.attn.in_proj_bias   |        1536       |\n",
      "| encoder.6.attn.out_proj.weight |       262144      |\n",
      "|  encoder.6.attn.out_proj.bias  |        512        |\n",
      "|  encoder.6.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.6.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.6.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.6.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.6.ffnn.0.weight     |       65536       |\n",
      "|     encoder.6.ffnn.0.bias      |        128        |\n",
      "|    encoder.6.ffnn.3.weight     |       65536       |\n",
      "|     encoder.6.ffnn.3.bias      |        512        |\n",
      "|     encoder.6.norm1.weight     |        512        |\n",
      "|      encoder.6.norm1.bias      |        512        |\n",
      "|     encoder.6.norm2.weight     |        512        |\n",
      "|      encoder.6.norm2.bias      |        512        |\n",
      "|     encoder.6.norm3.weight     |        512        |\n",
      "|      encoder.6.norm3.bias      |        512        |\n",
      "| encoder.7.attn.in_proj_weight  |       786432      |\n",
      "|  encoder.7.attn.in_proj_bias   |        1536       |\n",
      "| encoder.7.attn.out_proj.weight |       262144      |\n",
      "|  encoder.7.attn.out_proj.bias  |        512        |\n",
      "|  encoder.7.ffnn_cls.0.weight   |       65536       |\n",
      "|   encoder.7.ffnn_cls.0.bias    |        128        |\n",
      "|  encoder.7.ffnn_cls.3.weight   |       65536       |\n",
      "|   encoder.7.ffnn_cls.3.bias    |        512        |\n",
      "|    encoder.7.ffnn.0.weight     |       65536       |\n",
      "|     encoder.7.ffnn.0.bias      |        128        |\n",
      "|    encoder.7.ffnn.3.weight     |       65536       |\n",
      "|     encoder.7.ffnn.3.bias      |        512        |\n",
      "|     encoder.7.norm1.weight     |        512        |\n",
      "|      encoder.7.norm1.bias      |        512        |\n",
      "|     encoder.7.norm2.weight     |        512        |\n",
      "|      encoder.7.norm2.bias      |        512        |\n",
      "|     encoder.7.norm3.weight     |        512        |\n",
      "|      encoder.7.norm3.bias      |        512        |\n",
      "|           out.weight           |        2048       |\n",
      "|            out.bias            |         4         |\n",
      "+--------------------------------+-------------------+\n",
      "Sum of trainable parameters: 10805766\n"
     ]
    }
   ],
   "source": [
    "import time, functools, torch, os,sys, random, fnmatch, psutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam,RAdam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from prettytable import PrettyTable\n",
    "import tqdm\n",
    "from pickle import load\n",
    "from IPython import display\n",
    "\n",
    "sys.path.insert(1, '../')\n",
    "#import trans_tdsm, utils\n",
    "import util.data_utils as utils\n",
    "import util.score_model as score_model\n",
    "import util.sdes as sdes\n",
    "import util.display\n",
    "\n",
    "# GPU device info\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:516\"\n",
    "os.system('nvidia-smi')\n",
    "\n",
    "# Set padding value used\n",
    "padding_value = 0.0\n",
    "\n",
    "dataset = \"dataset_2_padded_nentry\"\n",
    "preproc_dataset_name = 'ds2_diff_transforms'\n",
    "dataset_store_path = os.path.join(\"/eos/user/j/jthomasw/tdsm_encoder/datasets/\", preproc_dataset_name)\n",
    "transform = None\n",
    "transform_y = None\n",
    "mask = True\n",
    "jupyternotebook = True\n",
    "workingdir = \"./\"\n",
    "\n",
    "### SDE PARAMETERS ###\n",
    "SDE = 'VP'\n",
    "if SDE == 'VP':\n",
    "    beta_max = 1.0\n",
    "    beta_min = 0.01\n",
    "if SDE == 'VE':\n",
    "    sigma_max = 20.0\n",
    "    sigma_min = 0.1\n",
    "    \n",
    "### MODEL PARAMETERS ###\n",
    "n_feat_dim = 4\n",
    "embed_dim = 512\n",
    "hidden_dim = 128\n",
    "num_encoder_blocks = 8\n",
    "num_attn_heads = 16\n",
    "dropout_gen = 0\n",
    "\n",
    "# Instantiate stochastic differential equation\n",
    "if SDE == 'VP':\n",
    "    sde = sdes.VPSDE(beta_max=beta_max,beta_min=beta_min, device=device)\n",
    "if SDE == 'VE':\n",
    "    sde = sdes.VESDE(sigma_max=sigma_max,sigma_min=sigma_min,device=device)\n",
    "marginal_prob_std_fn = functools.partial(sde.marginal_prob)\n",
    "diffusion_coeff_fn = functools.partial(sde.sde)\n",
    "\n",
    "print('torch version: ', torch.__version__)\n",
    "print('Running on device: ', device)\n",
    "if torch.cuda.is_available():\n",
    "    print('Cuda used to build pyTorch: ',torch.version.cuda)\n",
    "    print('Current device: ', torch.cuda.current_device())\n",
    "    print('Cuda arch list: ', torch.cuda.get_arch_list())\n",
    "\n",
    "print('Working directory: ', workingdir)\n",
    "\n",
    "# Input files\n",
    "files_list_ = []\n",
    "for filename in os.listdir(dataset_store_path):\n",
    "    if fnmatch.fnmatch(filename, dataset + '*424To564.pt'):\n",
    "        files_list_.append(os.path.join(dataset_store_path, filename))\n",
    "print(files_list_)\n",
    "\n",
    "# Instantiate model\n",
    "model=score_model.Gen(n_feat_dim, embed_dim, hidden_dim, num_encoder_blocks, num_attn_heads, dropout_gen, marginal_prob_std=marginal_prob_std_fn)\n",
    "torch.save(model.state_dict(), 'initial_model.pt')\n",
    "table = PrettyTable(['Module name', 'Parameters listed'])\n",
    "t_params = 0\n",
    "for name_ , para_ in model.named_parameters():\n",
    "    if not para_.requires_grad: continue\n",
    "    param = para_.numel()\n",
    "    table.add_row([name_, param])\n",
    "    t_params+=param\n",
    "print(table)\n",
    "print(f'Sum of trainable parameters: {t_params}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fe119",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The following cell will call training methods from the trans_tdsm.py script so everything should be synchronised with what we can run on condor for the big jobs.\n",
    "\n",
    "Once you have a a fully trained model you can look at the sampling notebook to see how to generate samples and make some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa3b437",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4acac8975d24fdfa5627172b4be1128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/eos/user/j/jthomasw/tdsm_encoder/datasets/ds2_diff_transforms/dataset_2_padded_nentry424To564.pt']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3213/232421906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshower_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincident_energies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarginal_prob_std_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Accumulate batch loss per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mcumulative_epoch_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0;31m# collect dL/dx for any parameters (x) which have requires_grad = True via: x.grad += dL/dx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "### HYPERPARAMETERS ###\n",
    "train_ratio = 0.8\n",
    "batch_size = 128\n",
    "n_epochs = 200\n",
    "epochs = tqdm.notebook.trange(n_epochs)\n",
    "# Setup exponentially decaying learning rate\n",
    "initial_lr = 5e-4\n",
    "\n",
    "### Model ###\n",
    "model = score_model.Gen(n_feat_dim, embed_dim, hidden_dim, num_encoder_blocks, num_attn_heads, dropout_gen, marginal_prob_std=marginal_prob_std_fn)\n",
    "state_dict = torch.load('initial_model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "### optimiser ###\n",
    "optimiser = RAdam(model.parameters(),lr=initial_lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimiser, gamma=0.99)\n",
    "\n",
    "output_directory = workingdir+'/training_'+datetime.now().strftime('%Y%m%d_%H%M')+'_'+preproc_dataset_name+'/'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "av_training_losses_per_epoch = []\n",
    "av_testing_losses_per_epoch = []\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(8,4))\n",
    "dh = display.display(fig, display_id=True)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_yscale('log')\n",
    "ax[1].set_xlabel('lr')\n",
    "ax[1].set_xlim(initial_lr*0.99**(n_epochs), initial_lr)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].tick_params('both', length=10, width=1, which='both')\n",
    "\n",
    "lrs_ = []\n",
    "\n",
    "print(files_list_)\n",
    "eps_ = []\n",
    "for epoch in epochs:\n",
    "    eps_.append(epoch)\n",
    "    # Create/clear per epoch variables\n",
    "    cumulative_epoch_loss = 0.\n",
    "    cumulative_test_epoch_loss = 0.\n",
    "\n",
    "    file_counter = 0\n",
    "    n_training_showers = 0\n",
    "    n_testing_showers = 0\n",
    "    training_batches_per_epoch = 0\n",
    "    testing_batches_per_epoch = 0\n",
    "\n",
    "    # Load files\n",
    "    for filename in files_list_:\n",
    "        custom_data = utils.cloud_dataset(filename, device=device)\n",
    "        train_size = int(train_ratio * len(custom_data.data))\n",
    "        test_size = len(custom_data.data) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(custom_data, [train_size, test_size])\n",
    "        n_training_showers+=train_size\n",
    "        n_testing_showers+=test_size\n",
    "        \n",
    "        # Load clouds for each epoch of data dataloaders length will be the number of batches\n",
    "        shower_loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        shower_loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Accumuate number of batches per epoch\n",
    "        training_batches_per_epoch += len(shower_loader_train)\n",
    "        testing_batches_per_epoch += len(shower_loader_test)\n",
    "\n",
    "        # Load shower batch for training\n",
    "        for i, (shower_data,incident_energies) in enumerate(shower_loader_train,0):\n",
    "            # Move model to device and set dtype as same as data (note torch.double works on both CPU and GPU)\n",
    "            model.to(device, shower_data.dtype)\n",
    "            model.train()\n",
    "            shower_data = shower_data.to(device)\n",
    "            incident_energies = incident_energies.to(device)\n",
    "\n",
    "            if len(shower_data) < 1:\n",
    "                print('Very few hits in shower: ', len(shower_data))\n",
    "                continue\n",
    "            # Zero any gradients from previous steps\n",
    "            optimiser.zero_grad()\n",
    "            # Loss average for each batch\n",
    "            loss = score_model.loss_fn(model, shower_data, incident_energies, marginal_prob_std_fn, padding_value, device=device, addmask=1)\n",
    "            # Accumulate batch loss per epoch\n",
    "            cumulative_epoch_loss+=float(loss)\n",
    "            # collect dL/dx for any parameters (x) which have requires_grad = True via: x.grad += dL/dx\n",
    "            loss.backward()\n",
    "            # Update value of x += -lr * x.grad\n",
    "            optimiser.step()\n",
    "\n",
    "        # Testing on subset of file\n",
    "        for i, (shower_data,incident_energies) in enumerate(shower_loader_test,0):\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                shower_data = shower_data.to(device)\n",
    "                incident_energies = incident_energies.to(device)\n",
    "                test_loss = score_model.loss_fn(model, shower_data, incident_energies, marginal_prob_std_fn, padding_value, device=device, addmask=1)\n",
    "                cumulative_test_epoch_loss+=float(test_loss)\n",
    "\n",
    "    # Calculate average loss per epoch\n",
    "    av_training_losses_per_epoch.append(cumulative_epoch_loss/training_batches_per_epoch)\n",
    "    av_testing_losses_per_epoch.append(cumulative_test_epoch_loss/testing_batches_per_epoch)\n",
    "    \n",
    "    lr_ = optimiser.param_groups[0]['lr']\n",
    "    epochs.set_description('Average Loss: {:5f}(Train) {:5f}(Test) {:5f}(lr)'.format(cumulative_epoch_loss/training_batches_per_epoch, cumulative_test_epoch_loss/testing_batches_per_epoch, lr_))\n",
    "    ax[0].plot(av_training_losses_per_epoch[1:], c='blue', label='training')\n",
    "    ax[0].plot(av_testing_losses_per_epoch[1:], c='red', label='testing')\n",
    "    \n",
    "    # End of epoch, change the learning rate\n",
    "    before_lr = optimiser.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    after_lr = optimiser.param_groups[0]['lr']\n",
    "    lrs_.append(before_lr)\n",
    "    ax[1].plot(lrs_[1:], av_training_losses_per_epoch[1:], c='blue')\n",
    "    if epoch == 0:\n",
    "        ax[0].legend(loc='upper right')\n",
    "    dh.update(fig)\n",
    "    if n_epochs%5 == 0:\n",
    "        torch.save(model.state_dict(), output_directory+'ckpt_tmp_'+str(epoch)+'.pth')\n",
    "    \n",
    "fig.savefig(output_directory+'loss_v_epoch.png')\n",
    "torch.save(model.state_dict(), output_directory+'ckpt_tmp_'+str(epoch)+'.pth')\n",
    "\n",
    "util.display.plot_loss_vs_epoch(eps_, av_training_losses_per_epoch, av_testing_losses_per_epoch, odir=output_directory, zoom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a39c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
